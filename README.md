# OLS_Regression_Assumptions_Explained_Python
This notebook presents a complete real-world simulation and analysis of **Ordinary Least Squares (OLS) Regression**. It is designed for those who are learning **data science/statistics** and want to understand not just how to fit a regression model but how to evaluate its **validity** using **OLS assumptions**.

## 📌 Project Highlights

- 📊 Simulated a dataset with realistic variables:
  - **Education**, **Experience**, **Age** → features
  - **Salary** → target variable

- 🧠 Performed **Multiple Linear Regression** using `statsmodels.OLS`

- ✅ Interpreted key regression outputs:
  - Coefficients, t-values, p-values
  - R-squared, Adjusted R-squared
  - F-statistic
  - Confidence Intervals

- 🔍 Validated all **5 OLS Assumptions**:
  1. **Linearity**
  2. **Independence of Errors**
  3. **Homoscedasticity (Equal Variance)**
  4. **Normality of Residuals**
  5. **No Multicollinearity**

- 📈 Included all visualizations (residual plots, histogram, Q-Q plot, etc.)

- 🧪 Also covered:
  - **R-squared vs Adjusted R-squared**
  - **Type I and Type II errors**
  - **F-statistic formula explained**
  - Real-world interpretation of each assumption and violation remedies

---

## 🛠️ Technologies Used

- Python 3
- NumPy
- Pandas
- Statsmodels
- Matplotlib / Seaborn

---

## 🚀 Getting Started

Clone the repository and open the notebook:

```bash
git clone https://github.com/Pranav-Anil44/OLS_Regression_Assumptions_Explained_Python.git
cd OLS_Regression_Assumptions_Explained_Python

Author
Pranav A Kumar
Data Science Enthusiast | Transitioning from FinTech Software Engineer Role
🔗 LinkedIn:https://www.linkedin.com/in/pranav-a-kumar-2a39b4358/

Contributions
This project is part of my data science learning journey. Feedback and suggestions are always welcome!
